{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras Tuner.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The keras tuner is a library that helps me pickup the optimal set of hyperparameters for me Tensorflow program. The process is called hyperparameter tunig or hypertuning.\n",
        "Hyperparameters are the variables tht govern the trainng process and the topology  of an ML model. These variables remain constant over the training process and directly impact the performance of our ML program. Hyperparameters are of two types:\n",
        "\n",
        "\n",
        "1.   *Model Hyperparameters* which is influence model selection such as the number and width of hidden layers.\n",
        "2.   *Algorithm hyperparameters* which is influence the speed qualityt of the learning algorithm such as the learning rate for Stochastic Gradient Descent(SGD) and the number of nearest neighbors fpr a K Nearest Neighbors(KNN) classifier."
      ],
      "metadata": {
        "id": "ByZyiFJS2Vpz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RIcW9877HJ8y",
        "outputId": "be2113c2-1f80-4744-c6b9-0e9da092192e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras \n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q -U keras-tuner"
      ],
      "metadata": {
        "id": "i0ezME3iK-cS"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt"
      ],
      "metadata": {
        "id": "q2o0taY95Kzs"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download and prepare dataset**\n",
        "[fashion MMIST dataset](https://github.com/zalandoresearch/fashion-mnist)"
      ],
      "metadata": {
        "id": "0rYZQ1pV5fys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(img_train, label_train), (img_test, label_test) = keras.datasets.fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "ME1zhPXa50vL"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize pixel values between 0 and 1\n",
        "img_train = img_train.astype('float32') / 255.0\n",
        "img_test = img_test.astype('float32') / 255.0"
      ],
      "metadata": {
        "id": "T6n-dYP_6O7e"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define The Model**\n",
        "When I build a model for hypertunig, I also define the hyperpararmeters search space on addition to the model architecture. The model I set up for the hypertunig is called a hypermodel.\n",
        "I can define a hypermodel through two approaches:\n",
        "\n",
        "\n",
        "*   By using a model builder function.\n",
        "*   By subclassing the *Hypermodel* class of the Keras Tuner API\n",
        "\n"
      ],
      "metadata": {
        "id": "UVavsbQz62cZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_builder(hp):\n",
        "  model = keras.Sequential()\n",
        "  model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
        "\n",
        "  # Tune the number of units in the first Dense layer\n",
        "  # Choose an optimal value between 32-512\n",
        "  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
        "  model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
        "  model.add(keras.layers.Dense(10))\n",
        "\n",
        "  # Tune the learning rate for the optimizer\n",
        "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
        "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "ZLIs-iRL76IN"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instantiate the tuner and perform hypertunig**\n",
        "Instantiate the number of hypertuning. The Keras Tuner has four tuners available - *RandomSearch*, *Hyperband*, *BayesianOptimization*, and *SKlearn*.\n",
        "to Instantiate the Hyperband tuner, I must specify the hypermodel, the objective to optimize and the maximum number of the epochs to the train *(max_epochs)*."
      ],
      "metadata": {
        "id": "NSVc8IlI_srK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=10,\n",
        "                     factor=3,\n",
        "                     directory='my_dir',\n",
        "                     project_name='intro_to_kt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRPYEKbsAzS3",
        "outputId": "b22f982c-ac9e-4b5a-dead-ec37e83f9237"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Reloading Oracle from existing project my_dir/intro_to_kt/oracle.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Reloading Oracle from existing project my_dir/intro_to_kt/oracle.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Reloading Tuner from my_dir/intro_to_kt/tuner0.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Reloading Tuner from my_dir/intro_to_kt/tuner0.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Hyperband tuning algorithm uses adaptive resource allcation and early-stoping to quickly converge on a high-performing model. This is done using a sports championship style bracket. The algorithm trains a large number of models for a few epochs and carries forwards only the top-performing half of models to the next round. Hyperband determines the number of models to train in bracket by the computing 1+ log *factor* (max_epochs) and rounding it up to the nearest integer.\n",
        "\n",
        "Create a callback to stop training early after reaching a certain value for the validation loss."
      ],
      "metadata": {
        "id": "aMNdVgH5XaBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 5)"
      ],
      "metadata": {
        "id": "EndtgBczZRfv"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the hyperparameter search. The arguments for the search method are the same as those used for the *tf.keras.model.fit* in addition to the callback above."
      ],
      "metadata": {
        "id": "nQy3Y0coZqBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(img_train, label_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
        "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
        "is {best_hps.get('learning_rate')}.\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9Ik_o6HZpQH",
        "outputId": "33e20d03-3ceb-4296-c9d5-6fafc2d6b653"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
            "layer is 352 and the optimal learning rate for the optimizer\n",
            "is 0.001.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train the model**\n",
        "Find the optimal number of train the model with the hyperparameters obtained fron the search."
      ],
      "metadata": {
        "id": "0A9-beTYeyDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model with the optimal hyperparameter and train it on the data for 50 epochs\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "history = model.fit(img_train, label_train, epochs = 50, validation_split = 0.2)\n",
        "\n",
        "val_acc_per_epoch = history.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) +1\n",
        "print('Best epoch: %d' % (best_epoch,))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIHroL6Kewuw",
        "outputId": "ef545a4e-b17c-48f5-8467-15102a8b959d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4963 - accuracy: 0.8244 - val_loss: 0.4303 - val_accuracy: 0.8451\n",
            "Epoch 2/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.3701 - accuracy: 0.8657 - val_loss: 0.3865 - val_accuracy: 0.8621\n",
            "Epoch 3/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3337 - accuracy: 0.8770 - val_loss: 0.3381 - val_accuracy: 0.8776\n",
            "Epoch 4/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3078 - accuracy: 0.8865 - val_loss: 0.3404 - val_accuracy: 0.8802\n",
            "Epoch 5/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2880 - accuracy: 0.8929 - val_loss: 0.3193 - val_accuracy: 0.8857\n",
            "Epoch 6/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2739 - accuracy: 0.8981 - val_loss: 0.3245 - val_accuracy: 0.8831\n",
            "Epoch 7/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2624 - accuracy: 0.9016 - val_loss: 0.3199 - val_accuracy: 0.8865\n",
            "Epoch 8/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2488 - accuracy: 0.9063 - val_loss: 0.3079 - val_accuracy: 0.8886\n",
            "Epoch 9/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2383 - accuracy: 0.9109 - val_loss: 0.3213 - val_accuracy: 0.8867\n",
            "Epoch 10/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2290 - accuracy: 0.9138 - val_loss: 0.3174 - val_accuracy: 0.8913\n",
            "Epoch 11/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2179 - accuracy: 0.9179 - val_loss: 0.3382 - val_accuracy: 0.8845\n",
            "Epoch 12/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2105 - accuracy: 0.9200 - val_loss: 0.3062 - val_accuracy: 0.8951\n",
            "Epoch 13/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2041 - accuracy: 0.9240 - val_loss: 0.3466 - val_accuracy: 0.8817\n",
            "Epoch 14/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1930 - accuracy: 0.9275 - val_loss: 0.3408 - val_accuracy: 0.8845\n",
            "Epoch 15/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1903 - accuracy: 0.9286 - val_loss: 0.3368 - val_accuracy: 0.8909\n",
            "Epoch 16/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1815 - accuracy: 0.9316 - val_loss: 0.3164 - val_accuracy: 0.8962\n",
            "Epoch 17/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1743 - accuracy: 0.9347 - val_loss: 0.3319 - val_accuracy: 0.8925\n",
            "Epoch 18/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1707 - accuracy: 0.9359 - val_loss: 0.3248 - val_accuracy: 0.8931\n",
            "Epoch 19/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1662 - accuracy: 0.9361 - val_loss: 0.3376 - val_accuracy: 0.8930\n",
            "Epoch 20/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1575 - accuracy: 0.9410 - val_loss: 0.3557 - val_accuracy: 0.8920\n",
            "Epoch 21/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1512 - accuracy: 0.9436 - val_loss: 0.3502 - val_accuracy: 0.8963\n",
            "Epoch 22/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1509 - accuracy: 0.9426 - val_loss: 0.3586 - val_accuracy: 0.8911\n",
            "Epoch 23/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1464 - accuracy: 0.9448 - val_loss: 0.3500 - val_accuracy: 0.8961\n",
            "Epoch 24/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1409 - accuracy: 0.9471 - val_loss: 0.3729 - val_accuracy: 0.8889\n",
            "Epoch 25/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1353 - accuracy: 0.9499 - val_loss: 0.3596 - val_accuracy: 0.8944\n",
            "Epoch 26/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1334 - accuracy: 0.9505 - val_loss: 0.3632 - val_accuracy: 0.8950\n",
            "Epoch 27/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1301 - accuracy: 0.9504 - val_loss: 0.3724 - val_accuracy: 0.8949\n",
            "Epoch 28/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1264 - accuracy: 0.9533 - val_loss: 0.4023 - val_accuracy: 0.8903\n",
            "Epoch 29/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1240 - accuracy: 0.9541 - val_loss: 0.3743 - val_accuracy: 0.8978\n",
            "Epoch 30/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1192 - accuracy: 0.9555 - val_loss: 0.4254 - val_accuracy: 0.8896\n",
            "Epoch 31/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1195 - accuracy: 0.9550 - val_loss: 0.4696 - val_accuracy: 0.8824\n",
            "Epoch 32/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1126 - accuracy: 0.9578 - val_loss: 0.4254 - val_accuracy: 0.8922\n",
            "Epoch 33/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1130 - accuracy: 0.9572 - val_loss: 0.4362 - val_accuracy: 0.8938\n",
            "Epoch 34/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1088 - accuracy: 0.9588 - val_loss: 0.4531 - val_accuracy: 0.8919\n",
            "Epoch 35/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1062 - accuracy: 0.9595 - val_loss: 0.4268 - val_accuracy: 0.8900\n",
            "Epoch 36/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1036 - accuracy: 0.9617 - val_loss: 0.4403 - val_accuracy: 0.8934\n",
            "Epoch 37/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1002 - accuracy: 0.9625 - val_loss: 0.4855 - val_accuracy: 0.8903\n",
            "Epoch 38/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0964 - accuracy: 0.9647 - val_loss: 0.4592 - val_accuracy: 0.8955\n",
            "Epoch 39/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0978 - accuracy: 0.9632 - val_loss: 0.4487 - val_accuracy: 0.8916\n",
            "Epoch 40/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0927 - accuracy: 0.9654 - val_loss: 0.4692 - val_accuracy: 0.8942\n",
            "Epoch 41/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0923 - accuracy: 0.9651 - val_loss: 0.4629 - val_accuracy: 0.8898\n",
            "Epoch 42/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0896 - accuracy: 0.9659 - val_loss: 0.5039 - val_accuracy: 0.8918\n",
            "Epoch 43/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0872 - accuracy: 0.9670 - val_loss: 0.4916 - val_accuracy: 0.8905\n",
            "Epoch 44/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0851 - accuracy: 0.9680 - val_loss: 0.5244 - val_accuracy: 0.8868\n",
            "Epoch 45/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0831 - accuracy: 0.9691 - val_loss: 0.4955 - val_accuracy: 0.8888\n",
            "Epoch 46/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0829 - accuracy: 0.9690 - val_loss: 0.5044 - val_accuracy: 0.8922\n",
            "Epoch 47/50\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0811 - accuracy: 0.9695 - val_loss: 0.5225 - val_accuracy: 0.8948\n",
            "Epoch 48/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0800 - accuracy: 0.9697 - val_loss: 0.5099 - val_accuracy: 0.8932\n",
            "Epoch 49/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0764 - accuracy: 0.9718 - val_loss: 0.5400 - val_accuracy: 0.8867\n",
            "Epoch 50/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0721 - accuracy: 0.9730 - val_loss: 0.5433 - val_accuracy: 0.8925\n",
            "Best epoch: 29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Re-instantiate the hypermodel and the train it with the number of epochs from above."
      ],
      "metadata": {
        "id": "PUT4Mmldgg7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hypermodel = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Retrain the model\n",
        "hypermodel.fit(img_train, label_train, epochs = best_epoch, validation_split = 0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFXygY_QgwRo",
        "outputId": "30e2d657-0811-4199-e664-187d9702078f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/29\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4988 - accuracy: 0.8240 - val_loss: 0.3929 - val_accuracy: 0.8566\n",
            "Epoch 2/29\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3729 - accuracy: 0.8648 - val_loss: 0.3834 - val_accuracy: 0.8586\n",
            "Epoch 3/29\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3321 - accuracy: 0.8779 - val_loss: 0.3460 - val_accuracy: 0.8732\n",
            "Epoch 4/29\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3071 - accuracy: 0.8872 - val_loss: 0.3291 - val_accuracy: 0.8802\n",
            "Epoch 5/29\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2883 - accuracy: 0.8925 - val_loss: 0.3191 - val_accuracy: 0.8873\n",
            "Epoch 6/29\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2719 - accuracy: 0.8983 - val_loss: 0.3512 - val_accuracy: 0.8717\n",
            "Epoch 7/29\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2602 - accuracy: 0.9022 - val_loss: 0.3485 - val_accuracy: 0.8820\n",
            "Epoch 8/29\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2480 - accuracy: 0.9072 - val_loss: 0.3347 - val_accuracy: 0.8842\n",
            "Epoch 9/29\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2357 - accuracy: 0.9101 - val_loss: 0.3190 - val_accuracy: 0.8900\n",
            "Epoch 10/29\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2273 - accuracy: 0.9150 - val_loss: 0.3058 - val_accuracy: 0.8920\n",
            "Epoch 11/29\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2174 - accuracy: 0.9180 - val_loss: 0.3276 - val_accuracy: 0.8870\n",
            "Epoch 12/29\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2099 - accuracy: 0.9216 - val_loss: 0.3432 - val_accuracy: 0.8871\n",
            "Epoch 13/29\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2022 - accuracy: 0.9238 - val_loss: 0.3191 - val_accuracy: 0.8910\n",
            "Epoch 14/29\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1953 - accuracy: 0.9264 - val_loss: 0.3113 - val_accuracy: 0.8957\n",
            "Epoch 15/29\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1880 - accuracy: 0.9292 - val_loss: 0.3195 - val_accuracy: 0.8917\n",
            "Epoch 16/29\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1794 - accuracy: 0.9326 - val_loss: 0.3390 - val_accuracy: 0.8907\n",
            "Epoch 17/29\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1760 - accuracy: 0.9348 - val_loss: 0.3265 - val_accuracy: 0.8965\n",
            "Epoch 18/29\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1694 - accuracy: 0.9365 - val_loss: 0.3614 - val_accuracy: 0.8863\n",
            "Epoch 19/29\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1656 - accuracy: 0.9380 - val_loss: 0.3657 - val_accuracy: 0.8878\n",
            "Epoch 20/29\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1586 - accuracy: 0.9410 - val_loss: 0.3463 - val_accuracy: 0.8935\n",
            "Epoch 21/29\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1557 - accuracy: 0.9408 - val_loss: 0.3418 - val_accuracy: 0.8929\n",
            "Epoch 22/29\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1503 - accuracy: 0.9430 - val_loss: 0.3568 - val_accuracy: 0.8938\n",
            "Epoch 23/29\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1459 - accuracy: 0.9443 - val_loss: 0.3586 - val_accuracy: 0.8937\n",
            "Epoch 24/29\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1422 - accuracy: 0.9468 - val_loss: 0.3993 - val_accuracy: 0.8886\n",
            "Epoch 25/29\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1376 - accuracy: 0.9489 - val_loss: 0.3756 - val_accuracy: 0.8896\n",
            "Epoch 26/29\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1314 - accuracy: 0.9516 - val_loss: 0.3881 - val_accuracy: 0.8938\n",
            "Epoch 27/29\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1299 - accuracy: 0.9509 - val_loss: 0.3771 - val_accuracy: 0.8953\n",
            "Epoch 28/29\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1256 - accuracy: 0.9525 - val_loss: 0.3891 - val_accuracy: 0.8913\n",
            "Epoch 29/29\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1267 - accuracy: 0.9527 - val_loss: 0.4058 - val_accuracy: 0.8919\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f09ec4222d0>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To finish this day, evaluate the hypermodel on the test data."
      ],
      "metadata": {
        "id": "PvwM0jmBjUvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = hypermodel.evaluate(img_test, label_test)\n",
        "print('[test_loss, test_accuracy]:', eval_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXe5VF05jfHO",
        "outputId": "8e692db0-dc8b-40d4-df86-24e60b269644"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.4491 - accuracy: 0.8892\n",
            "[test_loss, test_accuracy]: [0.4491038918495178, 0.88919997215271]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *my_dir/intro_to_kit* directory contains detailed logs and checkpoints for the trail (model configuration) run during the hyperparameter search. If the re-run hyperparameter search, the Keras Tuner uses the exising state from these logs to resume the search. To disable this behavior, pass an additional *overwrite = True* argument instantiating the tuner."
      ],
      "metadata": {
        "id": "s5ervaXEj53H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "moMKokPBk4ny"
      },
      "execution_count": 36,
      "outputs": []
    }
  ]
}